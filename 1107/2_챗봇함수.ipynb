{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1fd468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7adb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatbot_function import get_menu,get_order_price,set_order\n",
    "from chatbot_responseV2  import get_first_chatbot_response,get_followup_chatbot_response,chat_with_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e579d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n",
      "log resp : ChatCompletion(id='chatcmpl-CZA92cNGM51dBRClBC6YwyGWgQEd3', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=FunctionCall(arguments='{}', name='get_menu'), tool_calls=None))], created=1762496512, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_4c2851f862', usage=CompletionUsage(completion_tokens=10, prompt_tokens=365, total_tokens=375, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "log  function_call\n",
      "â†ª: FunctionCall(arguments='{}', name='get_menu')\n",
      "log args\n",
      "â†ª: {}\n",
      "log result\n",
      "â†ª: {'menu': {'ìŠˆí¼ ìŠˆí”„ë¦¼': 10000, 'ì•„ì´ë¦¬ì‰¬ í¬í…Œì´í† ': 11000, 'ìŠ¤íŒŒì´ìŠ¤ ì¹˜í‚¨': 12000, 'ìŠˆí”„ë¦¼ ì•Œí”„ë ˆë„': 13000}, 'size': {'ë ˆê·¤ëŸ¬': 0, 'ë¯¸ë””ì—„': 2000, 'ë¼ì§€': 5000, 'íŒ¨ë°€ë¦¬': 10000}}\n",
      "log resp : ChatCompletion(id='chatcmpl-CZA9veK7niqoVt3DIOZtApKfBLZlH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='ì±—ë´‡ ê¸°ëŠ¥ê³¼ ë‹¤ë¥¸ ì§ˆë¬¸ì…ë‹ˆë‹¤. \\n\\nì£¼ë¬¸ ê°€ëŠ¥í•œ í”¼ì ë©”ë‰´ë¥¼ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•´ ì£¼ì„¸ìš”. í•„ìš”í•œ í”¼ì ì¢…ë¥˜, ì‚¬ì´ì¦ˆ, ìˆ˜ëŸ‰ì„ ì •í™•íˆ ì•Œë ¤ì£¼ì‹œë©´ ì£¼ë¬¸ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1762496567, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_4c2851f862', usage=CompletionUsage(completion_tokens=49, prompt_tokens=699, total_tokens=748, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "log  function_call\n",
      "â†ª: None\n",
      "log resp : ChatCompletion(id='chatcmpl-CZAADpmW8Sz9Hp5ASYelaAxIyg3sG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='ì£„ì†¡í•˜ì§€ë§Œ, \"ìŠ¤íŒŒì´ìŠ¤ ì¹˜í‚¨\" ë©”ë‰´ëŠ” ì—†ìŠµë‹ˆë‹¤.  \\nì£¼ë¬¸ ê°€ëŠ¥í•œ ë©”ë‰´ ì¤‘ì—ì„œ ì„ íƒí•´ ì£¼ì„¸ìš”:  \\n- ìŠˆí¼ ìŠˆí”„ë¦¼  \\n- ì•„ì¼ë¦¬ì‰¬ í¬í…Œì´í†   \\n- ìŠ¤íŒŒì´ì‹œ ì¹ ë¦¬  \\n- ìŠˆí”„ë¦¼ ì•Œí”„ë ˆë„  \\n\\nì‚¬ì´ì¦ˆì™€ ìˆ˜ëŸ‰ë„ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1762496585, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_4c2851f862', usage=CompletionUsage(completion_tokens=77, prompt_tokens=771, total_tokens=848, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "log  function_call\n",
      "â†ª: None\n",
      "log resp : ChatCompletion(id='chatcmpl-CZABYcthUnWnblkdLqoKysSEuJMpc', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=FunctionCall(arguments='{\"pizza_name\":\"ìŠ¤íŒŒì´ì‹œ ì¹ ë¦¬\",\"pizza_size\":\"ë¼ì§€\",\"quantity\":1}', name='set_order'), tool_calls=None))], created=1762496668, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_4c2851f862', usage=CompletionUsage(completion_tokens=31, prompt_tokens=872, total_tokens=903, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "log  function_call\n",
      "â†ª: FunctionCall(arguments='{\"pizza_name\":\"ìŠ¤íŒŒì´ì‹œ ì¹ ë¦¬\",\"pizza_size\":\"ë¼ì§€\",\"quantity\":1}', name='set_order')\n",
      "log args\n",
      "â†ª: {'pizza_name': 'ìŠ¤íŒŒì´ì‹œ ì¹ ë¦¬', 'pizza_size': 'ë¼ì§€', 'quantity': 1}\n",
      "log result\n",
      "â†ª: {'pizza_name': 'ìŠ¤íŒŒì´ì‹œ ì¹ ë¦¬', 'pizza_size': 'ë¼ì§€', 'quantity': 1, 'unit_price': 5000, 'sub_total': 5000}\n",
      "log resp : ChatCompletion(id='chatcmpl-CZADZeoE5Oo5KFeQiY3hayBEkH44v', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='ì¶”ê°€ ì£¼ë¬¸í•˜ì‹¤ í”¼ì ì¢…ë¥˜, ì‚¬ì´ì¦ˆ, ìˆ˜ëŸ‰ ì•Œë ¤ì£¼ì„¸ìš”.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1762496793, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_4c2851f862', usage=CompletionUsage(completion_tokens=18, prompt_tokens=988, total_tokens=1006, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "log  function_call\n",
      "â†ª: None\n",
      "log resp : ChatCompletion(id='chatcmpl-CZADphZ6qE47xyANgUHoxRh8f6iSv', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=FunctionCall(arguments='{\"pizza_name\":\"ì•„ì¼ë¦¬ì‰¬ í¬í…Œì´í† \",\"pizza_size\":\"ë ˆê·¤ëŸ¬\",\"quantity\":1}', name='set_order'), tool_calls=None))], created=1762496809, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_4c2851f862', usage=CompletionUsage(completion_tokens=34, prompt_tokens=1029, total_tokens=1063, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "log  function_call\n",
      "â†ª: FunctionCall(arguments='{\"pizza_name\":\"ì•„ì¼ë¦¬ì‰¬ í¬í…Œì´í† \",\"pizza_size\":\"ë ˆê·¤ëŸ¬\",\"quantity\":1}', name='set_order')\n",
      "log args\n",
      "â†ª: {'pizza_name': 'ì•„ì¼ë¦¬ì‰¬ í¬í…Œì´í† ', 'pizza_size': 'ë ˆê·¤ëŸ¬', 'quantity': 1}\n",
      "log result\n",
      "â†ª: {'pizza_name': 'ì•„ì¼ë¦¬ì‰¬ í¬í…Œì´í† ', 'pizza_size': 'ë ˆê·¤ëŸ¬', 'quantity': 1, 'unit_price': 0, 'sub_total': 0}\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"## ğŸ• í”¼ì ì£¼ë¬¸ ì±—ë´‡\")\n",
    "\n",
    "    chat_output = gr.Chatbot(label=\"PizzaOrderBot\",type=\"messages\")\n",
    "    user_input = gr.Textbox(placeholder=\"ì˜ˆ: ìŠˆí¼ ìŠˆí”„ë¦¼ ì£¼ë¬¸, ì£¼ë¬¸ ì™„ë£Œ\", label=\"ë©”ì‹œì§€ ì…ë ¥\")\n",
    "    submit = gr.Button(\"ì „ì†¡\")\n",
    "\n",
    "    # State ì»´í¬ë„ŒíŠ¸ : ì•± ì‹¤í–‰ ì¤‘ì— ê°’ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©. ë³´ì´ì§€ëŠ” ì•ŠëŠ” ì»´í¬ë„ŒíŠ¸\n",
    "    # ëŒ€í™” ë‚´ìš© ê¸°ë¡\n",
    "    chat_history = gr.State([])   # [] ëŠ” ì´ˆê¸°ê°’\n",
    "    # ì£¼ë¬¸ ë‚´ìš© ê¸°ë¡\n",
    "    orders = gr.State({\"order_id\": None, \"content\": [], \"payment\": 0})\n",
    "\n",
    "     # ì „ì†¡ ë²„íŠ¼\n",
    "    submit.click(\n",
    "        chat_with_bot,\n",
    "        inputs=[user_input, chat_history, orders], #ordersë¥¼ chat_with_botì— ì „ë‹¬\n",
    "        outputs=[user_input, chat_output, orders], #chat_with_bot í•¨ìˆ˜ì— ë³€ê²½ëœ orders ë¦¬í„´\n",
    "    )\n",
    "   # ì…ë ¥ì°½ì—ì„œ ì—”í„°ë¡œ ì‹¤í–‰ \n",
    "    user_input.submit(\n",
    "        chat_with_bot,\n",
    "        inputs=[user_input, chat_history, orders],\n",
    "        outputs=[user_input, chat_output, orders],\n",
    "    )\n",
    "\n",
    "demo.launch(inline=False,debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64ea26d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2469b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt ì—ê²Œ ë³´ë‚´ëŠ” í•¨ìˆ˜ì˜ ìš”ì²­ì„ í…ìŠ¤íŠ¸ì—ì„œ chat_history ë¡œ ë³€ê²½.\n",
    "# í…ŒìŠ¤íŠ¸ step1\n",
    "'''\n",
    "user_input ='í”¼ì ì£¼ë¬¸. ë©”ë‰´ ë³´ì—¬ì£¼ì„¸ìš”'\n",
    "response = get_first_chatbot_response(user_input)\n",
    "print(response.model_dump_json(indent=2))'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4eb86cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„log fn_name: get_menu , args {}\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ step2\n",
    "'''\n",
    "import json\n",
    "fn_name = getattr(response.choices[0].message.function_call, \"name\", None)\n",
    "args = json.loads(response.choices[0].message.function_call.arguments)\n",
    "print(f'ğŸ”„log fn_name: {fn_name} , args {args}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db5457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # í…ŒìŠ¤íŠ¸ step3 : í•¨ìˆ˜ ì‹¤í–‰ \n",
    "'''\n",
    "func_response =  globals()[fn_name](**args)  \n",
    "# # í…ŒìŠ¤íŠ¸ step4 : í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼ë¡œ gpt ì‘ë‹µ ìš”ì²­\n",
    "followup = get_followup_chatbot_response(fn_name,func_response)\n",
    "# print(followup.model_dump_json(indent=2))\n",
    "print(followup.choices[0].message.content)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4046079d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„log fn_name: None\n",
      "ì£¼ë¬¸í•˜ì‹¤ í”¼ì ë©”ë‰´ ì´ë¦„ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì‚¬ì´ì¦ˆëŠ” ë¯¸ë””ì›€ìœ¼ë¡œ ì´í•´í–ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# user_input ='ë©”ë‰´ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”'\n",
    "# user_input ='ìŠ¤íŒŒì´ìŠ¤ ì¹˜í‚¨ ì£¼ë¬¸ í•©ë‹ˆë‹¤.'\n",
    "user_input ='ë¯¸ë””ì›€ ì£¼ë¬¸í•©ë‹ˆë‹¤.'\n",
    "response = get_chatbot_response(question=user_input)\n",
    "print(response)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "915f9e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735459f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
